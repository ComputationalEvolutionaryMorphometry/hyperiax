{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her er et første skud på beskrivelse af local updates (markdown, can feks indsættes øverst i localfast.ipynb). Der er sikkert fejl i det, skal kigge det igennem igen, men jeg tror den overordnede struktur er nogenlunde rigtig:\n",
    "Let $n$ be a node with parent $p$ and children $c_1,\\ldots,c_k$. Let $l_{p,n}$ denote the edge length from $p$ to $n$. Let $v_n$ be the value of $n$. We assume that $v_n|v_p\\simeq \\mathcal N(v_p,l_{p,n}\\Sigma(v_p,\\theta_p))$ where $\\Sigma(v_p)$ is the covariance matrix, a function of the node value $v_p$ and parameters $\\theta_p$.\n",
    "We wish to sample from the distribution $v_n|v_p,v_{c_1},\\ldots v_{c_n}$. We have\n",
    "$$p(v_n|v_p,c_1...,c_n) = \\frac{p(v_{c_1},\\ldots,v_{c_n}|v_p,v_n)p(v_n|v_p)}{p(v_{c_1},\\ldots,v_{c_n}|v_p)}= \\frac{p(v_{c_1}|v_n)\\cdots p(v_{c_n}|v_n)p(v_n|v_p)}{p(v_{c_1},\\ldots,v_{c_n}|v_p)}$$\n",
    "using that $v_{c_1}|v_n,\\ldots,v_{c_n}|v_n$ are independent.\n",
    "All parent conditional probabilities are Gaussian, and we write the densities on canonical form for exponential families, i.e. $p(v_n|v_p) = \\exp(-c_p+F_p^Tv_n-\\frac12 v_n^TH_pv_n)$ (see https://arxiv.org/abs/2203.04155). Note that $c=-\\log p(v;0,\\Sigma)$, $F=Hv$ and $H=\\Sigma^{-1}$. Write $H_{c_i}=l_{n,c_i}^{-1}\\Sigma(v_n,\\theta_n)^{-1}$. In this notation, we have\n",
    "$$\\log p(v_{c_i}|v_n)\n",
    "= \\mathrm{constant}-\\frac12(v_{c_i}-v_n)^Tl_{n,c_i}^{-1}\\Sigma(v_n,\\theta_n)^{-1}(v_{c_i}-v_n)\n",
    "= -c_{c_i}+F_{c_i}^Tv_n-\\frac12 v_n^TH_{c_i}v_n\n",
    "$$\n",
    "and thus\n",
    "\\begin{align}\n",
    "& \\log p(v_n|v_p,v_{c_1},\\ldots,v_{c_n}) \\\\\n",
    "& = -\\big(c_p+\\sum_{i=1}^n c_{c_i}\\big)+\\big(F_p+\\sum_{i=1}^n F_{c_i}^T\\big)v_n-\\frac12 v_n^T\\big(H_p+\\sum_{i=1}^n H_{c_i}\\big)v_n\n",
    "-\\log p(v_{c_1},\\ldots,v_{c_n}|v_p)\n",
    "\\ .\n",
    "\\end{align}\n",
    "We don’t need to wory about $\\log p(v_{c_1},\\ldots,v_{c_n}|v_p)$, since it cancels out in the MH step.\n",
    "In the MH step of the MCMC sampler, we sample a new value and parameters $v_n’,\\theta_n’$ based on $v_n,\\theta_n$ and accept/reject it by evaluating the log-ratio\n",
    "$$\\log p(v_n’|v_p,v_{c_1},\\ldots,v_{c_n})-\\log p(v_n|v_p,v_{c_1},\\ldots,v_{c_n})$$\n",
    "According to the above, to evaluate this we need $\\sum_{i=1}^n c_{c_i}$, $\\sum_{i=1}^n F_{c_i}^T$, and $\\sum_{i=1}^n H_{c_i}$ from the up operation with $H_{c_i}=l_{n,c_i}^{-1}\\Sigma(v_n,\\theta_n)^{-1}$, $F_{c_i}=H_{c_i}v_{c_i}$, and $c_{c_i}=-\\log \\phi(v_{c_i};0,l_{n,c_i}\\Sigma(v_n,\\theta_n))$ where $\\phi(x;0,\\Sigma)$ is the Gaussian density.\n",
    "This gives the operations\n",
    "#\n",
    "- Up operation:\n",
    "  - Compute $H_{c_i}=l_{n,c_i}^{-1}\\Sigma(v_n)^{-1}$\n",
    "  - Compute $F_{c_i}=H_{c_i}v_{c_i}$\n",
    "  - Compute $c_{c_i}=-\\log \\phi(v_{c_i};0,l_{n,c_i}\\Sigma(v_n))$\n",
    "- Reduce operation:\n",
    "  - Sum $\\sum_{i=1}^n c_{c_i}$, $\\sum_{i=1}^n F_{c_i}^T$, and $\\sum_{i=1}^n H_{c_i}$\n",
    "- Down operation:\n",
    "  - Compute $H_p=l_{p,n}^{-1}\\Sigma(v_p)^{-1}$\n",
    "  - Compute $F_p=H_pv_p$\n",
    "  - Compute $c_p=-\\log \\phi(v_n;0,l_{p,n}\\Sigma(v_p))$\n",
    "- Local update:\n",
    "  - Propose new $v_n’$ and $\\theta_n’$\n",
    "  - Compute acceptance ratio using the up and down results\n",
    "  - Accept or reject the proposal\n",
    "Note above that we only need to invert $\\Sigma(v_n,\\theta_n)$ one time to compute the up for all children.\n",
    "Nodes can be updated sequentially or in parallel with the same result as long as no node is the parent or child of another node that is being updated. This is achieved with a red/black node partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperiax\n",
    "from jax.random import PRNGKey, split\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from hyperiax.execution import OrderedExecutor, UnorderedExecutor\n",
    "from hyperiax.models import UpLambdaReducer, DownLambda, UpLambda, UpdateLambdaReducer\n",
    "from hyperiax.models.functional import pass_up\n",
    "from hyperiax.tree.topology import symmetric_topology\n",
    "from hyperiax.tree import HypTree\n",
    "from hyperiax.plotting import plot_tree_text, plot_tree_2d_scatter\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 None\n",
      "        ┌─────────┴─────────┐\n",
      "       None                None        \n",
      "   ┌────┴────┐         ┌────┴────┐     \n",
      "  None      None      None      None   \n",
      " ┌─┴──┐    ┌─┴──┐    ┌─┴──┐    ┌─┴──┐  \n",
      "None None None None None None None None\n"
     ]
    }
   ],
   "source": [
    "topology = symmetric_topology(height=3, degree=2)\n",
    "plot_tree_text(topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = HypTree(topology)\n",
    "\n",
    "tree.add_property('edge_length', shape=(1,))\n",
    "tree.add_property('obs_var', shape=(1,))\n",
    "tree.add_property('noise', shape=(d,))\n",
    "tree.add_property('value', shape=(d,))\n",
    "tree.add_property('H', shape=(d,d))\n",
    "tree.add_property('F', shape=(d,))\n",
    "tree.add_property('C', shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, k1 = split(key)\n",
    "tree.data['value'] = jax.random.normal(key, shape=tree.data['value'].shape)\n",
    "tree.data['noise'] = jax.random.normal(k1, shape=tree.data['noise'].shape)\n",
    "tree.data['edge_length'] = 1/(tree.node_depths+1) # for testing\n",
    "tree.data['obs_var'] = tree.data['edge_length']#jnp.ones_like(tree.data['obs_var'])*0.01\n",
    "repeated_eye = repeat(jnp.eye(d),'i j->n i j', n=len(tree))\n",
    "sigmas = tree.data['obs_var'][:,:,None]*repeated_eye\n",
    "tree.data['H'] = repeated_eye/tree.data['obs_var'][:,:,None]\n",
    "tree.data['F'] = jnp.einsum('nij,nj->ni', tree.data['H'], tree.data['value'])\n",
    "tree.data['C'] = -jax.scipy.stats.multivariate_normal.logpdf(tree.data['value'],jnp.zeros(d),sigmas)\n",
    "\n",
    "# only leaf values matter - rest can be assumed undefined despite having value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Up operation:\n",
    "  - Compute $H_{c_i}=l_{n,c_i}^{-1}\\Sigma(v_n)^{-1}$\n",
    "  - Compute $F_{c_i}=H_{c_i}v_{c_i}$\n",
    "  - Compute $c_{c_i}=-\\log \\phi(v_{c_i};0,l_{n,c_i}\\Sigma(v_n))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(value):\n",
    "    return repeat(jnp.eye(value.shape[-1]), 'i j -> n i j', n=value.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up(value, edge_length, parent_value, params):\n",
    "    H = (1/edge_length[:,:,None])*jnp.linalg.inv(sigma(parent_value))\n",
    "    F = jnp.einsum('bij,bj->bi', H, value)\n",
    "    C = -jax.scipy.stats.multivariate_normal.logpdf(value,jnp.zeros(value.shape[-1]),sigma(value))\n",
    "    return {'H': H, 'F': F, 'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(child_H, child_F, child_C, params):\n",
    "    return {'H': child_H, 'F': child_F, 'C': child_C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UpLambdaReducer(up, transform, {'H': 'sum', 'F': 'sum', 'C': 'sum'})\n",
    "exe = OrderedExecutor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe.up(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down():\n",
    "    ## not sure about equations and what to pass\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Local update:\n",
    "  - Propose new $v_n’$ and $\\theta_n’$\n",
    "  - Compute acceptance ratio using the up and down results\n",
    "  - Accept or reject the proposal\n",
    "\n",
    "\\begin{align}\n",
    "& \\log p(v_n|v_p,v_{c_1},\\ldots,v_{c_n}) \\\\\n",
    "& = -\\big(c_p+\\sum_{i=1}^n c_{c_i}\\big)+\\big(F_p+\\sum_{i=1}^n F_{c_i}^T\\big)v_n-\\frac12 v_n^T\\big(H_p+\\sum_{i=1}^n H_{c_i}\\big)v_n\n",
    "-\\log p(v_{c_1},\\ldots,v_{c_n}|v_p)\n",
    "\\ .\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(child_H, child_F, child_C, parent_C, parent_F, parent_H, value, leaf_mask, root_mask, **kwargs):\n",
    "    v = value ## propose instead\n",
    "    #theta = ...\n",
    "    # do this batched\n",
    "    #ll = - (parent_C + child_C) + (parent_F + child_F.T)-0.5*v.T*(parent_H + child_H)*v\n",
    "    accepted = jnp.ones(v.shape[0]) # properly calculate this\n",
    "\n",
    "    new_val = jnp.where(accepted[:,None], v, value)\n",
    "    return_val = jnp.where(leaf_mask[:,None], value, new_val)\n",
    "    return {'value': return_val}\n",
    "\n",
    "def up2(H,C,F, **kwargs):\n",
    "    return {'H': H, 'C': C, 'F': F}\n",
    "\n",
    "model = UpdateLambdaReducer(up_fn=up2, update_fn=update, reductions={'H': 'sum', 'F': 'sum', 'C': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe = UnorderedExecutor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False]\n",
      "[False False False False]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add got incompatible shapes for broadcasting: (4, 2), (2, 4).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/hyperiax/hyperiax/execution/unorderedexecutor.py:15\u001b[0m, in \u001b[0;36mUnorderedExecutor.update\u001b[0;34m(self, tree, key, params)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, tree, key, params \u001b[38;5;241m=\u001b[39m {}):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel), UpdateReducer):\n\u001b[0;32m---> 15\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_reduce_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel), UpdateModel):\n\u001b[1;32m     17\u001b[0m         coloring \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mcoloring\n",
      "File \u001b[0;32m~/repos/hyperiax/hyperiax/execution/unorderedexecutor.py:90\u001b[0m, in \u001b[0;36mUnorderedExecutor._update_reduce_inner\u001b[0;34m(self, data, tree, params, key)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(tree\u001b[38;5;241m.\u001b[39mis_root[up_ref])\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(tree\u001b[38;5;241m.\u001b[39mis_leaf[up_ref])\n\u001b[0;32m---> 90\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparent_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnode_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfuse_scatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_root\u001b[49m\u001b[43m[\u001b[49m\u001b[43mup_ref\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleaf_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_leaf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mup_ref\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, val \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     95\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m data[k]\u001b[38;5;241m.\u001b[39mat[up_ref]\u001b[38;5;241m.\u001b[39mset(val)\n",
      "Cell \u001b[0;32mIn[59], line 4\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(child_H, child_F, child_C, parent_C, parent_F, parent_H, value, leaf_mask, root_mask, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m v \u001b[38;5;241m=\u001b[39m value \u001b[38;5;66;03m## propose instead\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#theta = ...\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m (parent_C \u001b[38;5;241m+\u001b[39m child_C) \u001b[38;5;241m+\u001b[39m (\u001b[43mparent_F\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchild_F\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mv\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m*\u001b[39m(parent_H \u001b[38;5;241m+\u001b[39m child_H)\u001b[38;5;241m*\u001b[39mv\n\u001b[1;32m      5\u001b[0m accepted \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mones(v\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m# properly calculate this\u001b[39;00m\n\u001b[1;32m      7\u001b[0m new_val \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(accepted[:,\u001b[38;5;28;01mNone\u001b[39;00m], v, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:271\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    269\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.11/site-packages/jax/_src/numpy/ufuncs.py:99\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x1, x2, \u001b[38;5;241m/\u001b[39m):\n\u001b[1;32m     98\u001b[0m   x1, x2 \u001b[38;5;241m=\u001b[39m promote_args(numpy_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, x1, x2)\n\u001b[0;32m---> 99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.11/site-packages/jax/_src/lax/lax.py:1599\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   1597\u001b[0m       result_shape\u001b[38;5;241m.\u001b[39mappend(non_1s[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1599\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1600\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: add got incompatible shapes for broadcasting: (4, 2), (2, 4)."
     ]
    }
   ],
   "source": [
    "exe.update(tree, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
